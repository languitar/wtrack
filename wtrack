#!/usr/bin/env python3

from __future__ import print_function

import argparse
try:
    import ConfigParser as configparser
except ImportError:
    import configparser
import errno
import os.path
try:
    import urllib2 as request
except ImportError:
    from urllib import request
import sys

import icalendar
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

pd.set_option('display.max_rows', 999999)
pd.set_option('display.float_format', lambda x: '%.2f' % x)

CONFIG_FILE = os.path.expanduser('~/.config/wtrack/config.ini')
DATA_DIR = os.path.expanduser('~/.local/share/wtrack')
TIMES_FILE = os.path.join(DATA_DIR, 'times.csv')
TARGETS_FILE = os.path.join(DATA_DIR, 'targets.csv')

_TIMES_COLUMNS = ['start', 'end', 'correction', 'description']
_TARGETS_COLUMNS = ['target', 'description']

_WEEKDAY_MAPPING = {
    0: 'monday',
    1: 'tuesday',
    2: 'wednesday',
    3: 'thursday',
    4: 'friday',
    5: 'saturday',
    6: 'sunday'
}

_CONFIG = None


def _normalize_date(dt):
    return dt.replace(hour=0, minute=0, second=0, microsecond=0)


def _read_data(filename):
    with open(filename, 'r') as fd:
        return pd.read_csv(fd, index_col=0)


def _read_times(filename):
    try:
        data = _read_data(filename)
        data['start'] = pd.to_datetime(data['start'])
        data['end'] = pd.to_datetime(data['end'])
        data['correction'] = pd.to_timedelta(data['correction'])
        data['description'] = data['description'].fillna('')
        data = data.sort_values('start')
        return data
    except IOError as error:
        if error.errno == errno.ENOENT:
            # file simply does not exist. We probably start from the beginning
            return pd.DataFrame(
                index=pd.DatetimeIndex([]),
                columns=_TIMES_COLUMNS)
        else:
            raise error


def _read_targets(filename):
    try:
        targets = _read_data(filename)
        targets.index = pd.to_datetime(targets.index)
        targets['target'] = pd.to_timedelta(targets['target'])
        targets = targets.sort_index()
        return targets
    except IOError as error:
        if error.errno == errno.ENOENT:
            # file simply does not exist. We probably start from the beginning
            return pd.DataFrame(
                index=pd.DatetimeIndex([]),
                columns=_TARGETS_COLUMNS)
        else:
            raise error


def _write_data(data, filename, columns):
    try:
        os.makedirs(os.path.dirname(filename))
    except OSError as error:
        if not (error.errno == errno.EEXIST and
                os.path.isdir(os.path.dirname(filename))):
            raise error
    with open(filename, 'w') as fd:
        data.to_csv(fd, columns=columns)


def _read_public_holidays(url):
    response = request.urlopen(url)
    calendar = icalendar.Calendar.from_ical(response.read())
    dates = []
    descriptions = []
    for component in calendar.walk():
        if component.name == "VEVENT":
            dates.append(component.get('dtstart').dt)
            descriptions.append(component.get('summary'))
    return pd.Series(descriptions, index=pd.to_datetime(dates))


_holidays = {}


def _get_holidays(year):
    global _holidays
    if int(year) not in _holidays:
        if _CONFIG.has_option('holidays', 'calendar'):
            _holidays[int(year)] = _read_public_holidays(
                _CONFIG.get('holidays', 'calendar').format(year=year))
        else:
            _holidays[int(year)] = pd.Series()
    return _holidays[int(year)]


def _get_default_target(date):
    if _normalize_date(date) in _get_holidays(date.year):
        return pd.Timedelta(0), _get_holidays(date.year)[
            _normalize_date(date)]
    else:
        target = _CONFIG.get('target_times', 'daily') \
            if _CONFIG.has_option('target_times', 'daily') else '8h'

        weekday = date.dayofweek
        assert weekday in _WEEKDAY_MAPPING

        if _CONFIG.has_option('target_times', _WEEKDAY_MAPPING[weekday]):
            target = _CONFIG.get('target_times',
                                 _WEEKDAY_MAPPING[weekday])

        return pd.Timedelta(target), ''


def _interpolate_targets(targets, start, end):
    new_index = pd.Series(np.concatenate([
        pd.date_range(
            _normalize_date(start),
            _normalize_date(end)),
        targets.index]))
    new_index.sort_values()
    new_index = new_index.drop_duplicates()
    targets = targets.reindex(new_index)

    print()

    def fill_missing_target(row):
        if not row['target'] is pd.NaT:
            return row
        else:
            date = _normalize_date(row['index'])
            target, description = _get_default_target(date)
            print(
                'Assuming target work time for {}: {:%H:%M} '
                '(description: {})'.format(
                    date.date().strftime("%Y-%m-%d"),
                    (pd.to_datetime('today') + target).to_pydatetime(),
                    description),
                file=sys.stderr)
            return pd.Series({'index': row['index'],
                              'target': target,
                              'description': description})

    return targets.reset_index().apply(
        fill_missing_target, axis=1).set_index('index')


def _warn_missing_entries(times, targets):

    should_work = targets[targets['target'].apply(
        lambda x: x.total_seconds()) > 0].index
    missing = should_work[~should_work.isin(times['start'].apply(
        lambda x: pd.to_datetime(x.date())))]
    missing_this_year = missing[
        missing > pd.to_datetime(
            pd.to_datetime('now').to_pydatetime().strftime("%Y"))].to_series()

    if not missing_this_year.empty:
        print()
        print("Missing entries:")
        for date, _ in missing_this_year.iteritems():
            print('  {:%Y-%m-%d}'.format(date.to_pydatetime()))


def _pretty_timedelta(delta):

    sign = ''
    date = pd.to_datetime('today')
    if delta.total_seconds() < 0:
        sign = '-'
        date = date - delta
    else:
        sign = '+'
        date = date + delta

    return '{}{:%H:%M}'.format(sign, date.to_pydatetime())


def main_track(args):
    times = _read_times(TIMES_FILE)
    targets = _read_targets(TARGETS_FILE)

    start = pd.to_datetime(args.start)
    end = pd.to_datetime(args.end)

    # apply date override
    if args.date:
        date = pd.to_datetime(args.date)
        start = start.replace(year=date.year, month=date.month, day=date.day)
        end = end.replace(year=date.year, month=date.month, day=date.day)

    correction = pd.Timedelta(args.correction)
    description = args.description

    # --- validity checks
    # start before end, same timestamp is allowed to simply input corrections
    if end < start:
        print(
            'ERROR: End time before start time '
            '(start: {}, end: {})'.format(start, end),
            file=sys.stderr)
        sys.exit(1)
    # overlaps
    overlaps = pd.concat([
        times[(times['end'] > start) & (times['end'] < end)],
        times[(times['start'] > start) & (times['start'] < end)],
        times[(times['start'] <= start) & (times['end'] >= end)]
    ])
    if not overlaps.empty:
        print(
            'ERROR: New entry overlaps with existing ones'
            '(start: {}, end: {}):\n{}'.format(start, end, overlaps),
            file=sys.stderr)
        sys.exit(1)
    # work past midnight
    if _normalize_date(end) > _normalize_date(start):
        print(
            'ERROR: Work across day boundary not supported '
            '(start: {}, end: {})'.format(start, end),
            file=sys.stderr)
        sys.exit(1)

    print('''Adding entry:
  {start:%Y-%m-%d}
    {start:%H:%M} - {end:%H:%M} ({correction})
    Description: {description}'''.format(
        start=start.to_pydatetime(),
        end=end.to_pydatetime(),
        correction=_pretty_timedelta(correction),
        description=description))

    times.loc[-1] = [start, end, correction, description]
    times = times.sort_values('start').reset_index(drop=True)

    # add missing targets
    targets = _interpolate_targets(targets,
                                   times['start'].min(),
                                   times['end'].max())

    _warn_missing_entries(times, targets)

    # if everything succeeded, write data
    _write_data(times, TIMES_FILE, _TIMES_COLUMNS)
    _write_data(targets, TARGETS_FILE, _TARGETS_COLUMNS)


def main_target(args):
    targets = _read_targets(TARGETS_FILE)

    date = _normalize_date(pd.to_datetime(args.date))

    if args.target is None:
        # just show the report

        if date not in targets.index:
            # not in database so far
            target, description = _get_default_target(date)
            print('Predicted target work time for {}: '
                  '{} (description: {})'.format(date, target, description))
        else:
            row = targets.loc[date]
            print('Target work time for {}: {} (description: {})'.format(
                date, row['target'], row['description']))

    else:
        # insert a new target

        target = pd.to_timedelta(args.target)
        print('Setting new target for {}: {} (description: )'.format(
            date, target, args.description))
        targets.loc[date] = [target, args.description]
        _write_data(targets, TARGETS_FILE, _TARGETS_COLUMNS)


def main_report(args):
    times = _read_times(TIMES_FILE)
    targets = _read_targets(TARGETS_FILE)

    # ensure that we have targets for all data we know
    targets = _interpolate_targets(targets,
                                   times['start'].min(),
                                   times['end'].max())

    raw_hours = times['end'] - times['start']
    raw_hours.replace(pd.NaT, pd.Timedelta(0))
    times['worktime'] = raw_hours + times['correction'].fillna(0)
    times.index = times['start'].apply(_normalize_date)

    deltas = times[['worktime']]
    deltas = deltas.resample('1d').sum()
    deltas['target'] = targets['target'].reindex(deltas.index)
    deltas['diff'] = deltas['worktime'] - deltas['target']

    # limit to user choice
    deltas = deltas[deltas.index >= pd.to_datetime(args.since)]

    # resample according to desired report type
    deltas = deltas.resample(args.frequency).sum()

    # generate the desired report
    plot_type = 'bar'
    if args.report == 'total':
        data = deltas['worktime'].apply(
            lambda x: x / np.timedelta64(1, 's') /  60 / 60)
    elif args.report == 'delta':
        data = deltas['diff'].apply(
            lambda x: x / np.timedelta64(1, 's') /  60 / 60)
    elif args.report == 'average':
        plot_type = 'box'
        data = deltas
        data['dates'] = data.index
        data['weekday'] = data.index.weekday
        data = data.pivot(index='dates', columns='weekday', values='diff')
        data = data.applymap(lambda x: x.total_seconds() / 60 / 60
                                       if x is not pd.NaT else np.NaN)
    else:
        assert False

    if args.graphical:
        fig = plt.figure()
        data.plot(kind=plot_type, ax=fig.gca())
        fig.tight_layout()
        plt.show()
    else:
        print(data)
        print(data.describe())


def main_check(args):
    times = _read_times(TIMES_FILE)
    targets = _read_targets(TARGETS_FILE)

    _warn_missing_entries(times, targets)


def main():
    global _CONFIG

    # config file
    _CONFIG = configparser.ConfigParser()
    _CONFIG.read([CONFIG_FILE])

    # command line parsing
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    subparsers = parser.add_subparsers(title='subcommands')

    track = subparsers.add_parser(
        'track',
        description='Add a bunch of work',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    track.set_defaults(func=main_track)
    track.add_argument(
        '-c', '--correction',
        metavar='TIMEDELTA',
        default='-0.5h',
        help='correction factor as pandas-parseable timedelta')
    track.add_argument(
        '-d', '--date',
        metavar='DATE',
        help='Allows to specify a date that is automatically assumed for '
             'times specified in start and end. Must be parseable by pandas.')
    track.add_argument(
        'start',
        help='start time of work, pandas-parseable format')
    track.add_argument(
        'end',
        help='end time of work, pandas-parseable format')
    track.add_argument(
        'description',
        default='',
        nargs='?',
        help='description of activity')

    target = subparsers.add_parser(
        'target',
        description='Get or set the target work time for a day',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    target.set_defaults(func=main_target)
    target.add_argument(
        'date',
        help='date for which to set the target work time, pandas-parseable')
    target.add_argument(
        'target',
        metavar='TIMEDELTA',
        nargs='?',
        help='time to work at this day')
    target.add_argument(
        'description',
        default='',
        nargs='?',
        help='description of activity')

    report = subparsers.add_parser(
        'report',
        description='Reports on the work time',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    report.add_argument(
        '-s', '--since',
        default='1/1/{}'.format(pd.to_datetime('now').year),
        help='start reporting at this date')
    report.add_argument(
        '-g', '--graphical',
        default=False,
        action='store_true',
        help='Show report in a plot')
    report.add_argument(
        'frequency',
        help='sampling frequency for the report. Legal pandas frequency:'
             'http://pandas.pydata.org/pandas-docs/version/0.17.0/'
             'timeseries.html?highlight=now#offset-aliases')
    report.add_argument(
        'report',
        choices=['total', 'delta', 'average'],
        help='the kind of report to produce')
    report.set_defaults(func=main_report)

    report = subparsers.add_parser(
        'check',
        description='Checks for missing entries',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    report.set_defaults(func=main_check)

    args = parser.parse_args()
    try:
        main = args.func
    except AttributeError:
        parser.print_help()
    else:
        main(args)

if __name__ == '__main__':
    main()
