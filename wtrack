#!/usr/bin/env python2

from __future__ import print_function

import argparse
import ConfigParser
import errno
import os.path
import urllib2
import sys

import icalendar
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

pd.set_option('display.max_rows', 999999)

CONFIG_FILE = os.path.expanduser('~/.config/wtrack/config.ini')
DATA_DIR = os.path.expanduser('~/.local/share/wtrack')
TIMES_FILE = os.path.join(DATA_DIR, 'times.csv')
TARGETS_FILE = os.path.join(DATA_DIR, 'targets.csv')

_TIMES_COLUMNS = ['start', 'end', 'correction', 'description']
_TARGETS_COLUMNS = ['target', 'description']

_WEEKDAY_MAPPING = {
    0: 'monday',
    1: 'tuesday',
    2: 'wednesday',
    3: 'thursday',
    4: 'friday',
    5: 'saturday',
    6: 'sunday'
}

_CONFIG = None


def _read_data(filename):
    with open(filename, 'r') as fd:
        return pd.read_csv(fd, index_col=0)


def _read_times(filename):
    try:
        data = _read_data(filename)
        data['start'] = pd.to_datetime(data['start'])
        data['end'] = pd.to_datetime(data['end'])
        data['correction'] = pd.to_timedelta(data['correction'])
        data['description'] = data['description'].fillna('')
        data = data.sort('start')
        return data
    except IOError as error:
        if error.errno == errno.ENOENT:
            # file simply does not exist. We probably start from the beginning
            return pd.DataFrame(
                index=pd.DatetimeIndex([]),
                columns=_TIMES_COLUMNS)
        else:
            raise error


def _read_targets(filename):
    try:
        targets = _read_data(filename)
        targets.index = pd.to_datetime(targets.index)
        targets['target'] = pd.to_timedelta(targets['target'])
        targets = targets.sort_index()
        return targets
    except IOError as error:
        if error.errno == errno.ENOENT:
            # file simply does not exist. We probably start from the beginning
            return pd.DataFrame(
                index=pd.DatetimeIndex([]),
                columns=_TARGETS_COLUMNS)
        else:
            raise error


def _write_data(data, filename, columns):
    try:
        os.makedirs(os.path.dirname(filename))
    except OSError as error:
        if not (error.errno == errno.EEXIST and
                os.path.isdir(os.path.dirname(filename))):
            raise error
    with open(filename, 'w') as fd:
        data.to_csv(fd, columns=columns)


def _read_public_holidays(url):
    response = urllib2.urlopen(url)
    calendar = icalendar.Calendar.from_ical(response.read())
    dates = []
    descriptions = []
    for component in calendar.walk():
        if component.name == "VEVENT":
            dates.append(component.get('dtstart').dt)
            descriptions.append(component.get('summary'))
    return pd.Series(descriptions, index=pd.to_datetime(dates))


_holidays = {}


def _get_holidays(year):
    global _holidays
    if int(year) not in _holidays:
        if _CONFIG.has_option('holidays', 'calendar'):
            _holidays[int(year)] = _read_public_holidays(
                _CONFIG.get('holidays', 'calendar').format(year=year))
        else:
            _holidays[int(year)] = pd.Series()
    return _holidays[int(year)]


def _get_default_target(date):
    if pd.datetools.normalize_date(date) in _get_holidays(date.year):
        return pd.Timedelta(0), _get_holidays(date.year)[
            pd.datetools.normalize_date(date)]
    else:
        target = _CONFIG.get('target_times', 'daily') \
            if _CONFIG.has_option('target_times', 'daily') else '8h'

        weekday = date.dayofweek
        assert weekday in _WEEKDAY_MAPPING

        if _CONFIG.has_option('target_times', _WEEKDAY_MAPPING[weekday]):
            target = _CONFIG.get('target_times',
                                 _WEEKDAY_MAPPING[weekday])

        return pd.Timedelta(target), ''


def _interpolate_targets(targets, start, end):
    new_index = pd.Series(np.concatenate([
        pd.date_range(
            pd.datetools.normalize_date(start),
            pd.datetools.normalize_date(end)),
        targets.index]))
    new_index.sort()
    new_index = new_index.drop_duplicates()
    targets = targets.reindex(new_index)

    def fill_missing_target(row):
        if not row['target'] is pd.NaT:
            return row
        else:
            date = pd.datetools.normalize_date(row['index'])
            target, description = _get_default_target(date)
            print(
                'Assuming target work time for {}: {} '
                '(description: {})'.format(date, target, description),
                file=sys.stderr)
            return pd.Series({'index': row['index'],
                              'target': target,
                              'description': description})

    return targets.reset_index().apply(
        fill_missing_target, axis=1).set_index('index')


def main_track(args):
    times = _read_times(TIMES_FILE)
    targets = _read_targets(TARGETS_FILE)

    start = pd.to_datetime(args.start)
    end = pd.to_datetime(args.end)
    correction = pd.to_datetime(args.correction)
    description = args.description

    # --- validity checks
    # start before end, same timestamp is allowed to simply input corrections
    if end < start:
        print(
            'ERROR: End time before start time '
            '(start: {}, end: {})'.format(start, end),
            file=sys.stderr)
        sys.exit(1)
    # overlaps
    overlaps = pd.concat([
        times[(times['end'] > start) & (times['end'] < end)],
        times[(times['start'] > start) & (times['start'] < end)],
        times[(times['start'] <= start) & (times['end'] >= end)]
    ])
    if not overlaps.empty:
        print(
            'ERROR: New entry overlaps with existing ones'
            '(start: {}, end: {}):\n{}'.format(start, end, overlaps),
            file=sys.stderr)
        sys.exit(1)
    # work past midnight
    if pd.datetools.normalize_date(end) > pd.datetools.normalize_date(start):
        print(
            'ERROR: Work across day boundary not supported '
            '(start: {}, end: {})'.format(start, end),
            file=sys.stderr)
        sys.exit(1)

    print('''Adding entry:
  Start: {start}
  End: {end}
  Correction: {correction}
  Description: {description}'''.format(
        start=start, end=end, correction=correction, description=description))

    times.loc[len(times)] = [start, end, correction, description]
    times = times.sort('start')

    # add missing targets
    targets = _interpolate_targets(targets,
                                   times['start'].min(),
                                   times['end'].max())

    # if everything succeeded, write data
    _write_data(times, TIMES_FILE, _TIMES_COLUMNS)
    _write_data(targets, TARGETS_FILE, _TARGETS_COLUMNS)


def main_target(args):
    targets = _read_targets(TARGETS_FILE)

    date = pd.datetools.normalize_date(pd.to_datetime(args.date))

    if args.target is None:
        # just show the report

        if date not in targets.index:
            # not in database so far
            target, description = _get_default_target(date)
            print('Predicted target work time for {}: '
                  '{} (description: {})'.format(date, target, description))
        else:
            row = targets.loc[date]
            print('Target work time for {}: {} (description: {})'.format(
                date, row['target'], row['description']))

    else:
        # insert a new target

        target = pd.to_timedelta(args.target)
        print('Setting new target for {}: {} (description: )'.format(
            date, target, args.description))
        targets.loc[date] = [target, args.description]
        _write_data(targets, TARGETS_FILE, _TARGETS_COLUMNS)


def main_report(args):
    times = _read_times(TIMES_FILE)
    targets = _read_targets(TARGETS_FILE)

    # ensure that we have targets for all data we know
    targets = _interpolate_targets(targets,
                                   times['start'].min(),
                                   times['end'].max())

    raw_hours = times['end'] - times['start']
    raw_hours.replace(pd.NaT, pd.Timedelta(0))
    times['worktime'] = raw_hours + times['correction'].fillna(0)
    times.index = times['start'].apply(pd.datetools.normalize_date)

    deltas = times[['worktime']]
    deltas = deltas.resample('1d', how='sum')
    deltas['target'] = targets['target'].reindex(deltas.index)
    deltas['diff'] = deltas['worktime'] - deltas['target']

    # limit to user choice
    deltas = deltas[deltas.index >= pd.to_datetime(args.since)]

    # resample according to desired report type
    deltas = deltas.resample(args.frequency, how='sum')

    # generate the desired report
    if args.report == 'total':
        data = deltas['worktime'].apply(
            lambda x: x.astype(float) / 1000000000 / 60 / 60)
    elif args.report == 'delta':
        data = deltas['diff'].apply(
            lambda x: x.astype(float) / 1000000000 / 60 / 60)
    else:
        assert False

    if args.graphical:
        fig = plt.figure()
        data.plot(kind='bar')
        fig.tight_layout()
        plt.show()
    else:
        print(data)


def main():
    global _CONFIG

    # config file
    _CONFIG = ConfigParser.ConfigParser()
    _CONFIG.read([CONFIG_FILE])

    # command line parsing
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    subparsers = parser.add_subparsers(title='subcommands')

    track = subparsers.add_parser(
        'track',
        description='Add a bunch of work',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    track.set_defaults(func=main_track)
    track.add_argument(
        '-c', '--correction',
        metavar='TIMEDELTA',
        default='-0.5h',
        help='correction factor as pandas-parseable timedelta')
    track.add_argument(
        'start',
        help='start time of work, pandas-parseable format')
    track.add_argument(
        'end',
        help='end time of work, pandas-parseable format')
    track.add_argument(
        'description',
        default='',
        nargs='?',
        help='description of activity')

    target = subparsers.add_parser(
        'target',
        description='Get or set the target work time for a day',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    target.set_defaults(func=main_target)
    target.add_argument(
        'date',
        help='date for which to set the target work time, pandas-parseable')
    target.add_argument(
        'target',
        metavar='TIMEDELTA',
        nargs='?',
        help='time to work at this day')
    target.add_argument(
        'description',
        default='',
        nargs='?',
        help='description of activity')

    report = subparsers.add_parser(
        'report',
        description='Reports on the work time',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    report.add_argument(
        '-s', '--since',
        default='1/1/{}'.format(pd.to_datetime('now').year),
        help='start reporting at this date')
    report.add_argument(
        '-g', '--graphical',
        default=False,
        action='store_true',
        help='Show report in a plot')
    report.add_argument(
        'frequency',
        help='sampling frequency for the report. Legal pandas frequency:'
             'http://pandas.pydata.org/pandas-docs/version/0.17.0/'
             'timeseries.html?highlight=now#offset-aliases')
    report.add_argument(
        'report',
        choices=['total', 'delta'],
        help='the kind of report to produce')
    report.set_defaults(func=main_report)

    args = parser.parse_args()
    args.func(args)

if __name__ == '__main__':
    main()

